{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech_recognition_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNMD5M6mQ2YY"
      },
      "source": [
        "# Project: Speech Recognition with RNNs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKehhGDF-Qte"
      },
      "source": [
        "#### Part 1\n",
        "\n",
        "Implemented the LSTM RNN cell.\n",
        "\n",
        "#### Part 2 \n",
        "\n",
        "- Implemented a Bidirectional RNN.\n",
        "- Compared vanilla RNN, GRU, LSTM, and bidirectional VS unidirectional RNNs and reported their performance with respect to accuracy and time cost.\n",
        "\n",
        "#### Part 3 \n",
        "\n",
        "- Performed architecture optimisation.\n",
        "- Improved utilisation of the hidden state sequence output by the RNN, for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWGb-eUeXtex"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Using the Google [*Speech Commands*](https://www.tensorflow.org/tutorials/sequences/audio_recognition) v0.02 [1] dataset.\n",
        "\n",
        "[1] Warden, P. (2018). [Speech commands: A dataset for limited-vocabulary speech recognition](https://arxiv.org/abs/1804.03209). *arXiv preprint arXiv:1804.03209.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8LE3PgyPtdp"
      },
      "source": [
        "Set-up code and imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKX77IWYgCQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e1be4a3a-da52-49e8-812d-669dc7ae7f3e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt3KzJzBPdHU"
      },
      "source": [
        "import math\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read\n",
        "import librosa\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKoRxs89LGyh"
      },
      "source": [
        "Data provider class definition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKSnqpAJLVwx"
      },
      "source": [
        "class SpeechCommandsDataset(Dataset):\n",
        "    \"\"\"Google Speech Commands dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, root_dir, split):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the data files.\n",
        "            split    (string): In [\"train\", \"valid\", \"test\"].\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "\n",
        "        self.number_of_classes = len(self.get_classes())\n",
        "\n",
        "        self.class_to_file = defaultdict(list)\n",
        "\n",
        "        self.valid_filenames = self.get_valid_filenames()\n",
        "        self.test_filenames = self.get_test_filenames()\n",
        "\n",
        "        for c in self.get_classes():\n",
        "            file_name_list = sorted(os.listdir(self.root_dir + \"/data_speech_commands_v0.02/\" + c))\n",
        "            for filename in file_name_list:\n",
        "                if split == \"train\":\n",
        "                    if (filename not in self.valid_filenames[c]) and (filename not in self.test_filenames[c]):\n",
        "                        self.class_to_file[c].append(filename)\n",
        "                elif split == \"valid\":\n",
        "                    if filename in self.valid_filenames[c]:\n",
        "                        self.class_to_file[c].append(filename)\n",
        "                elif split == \"test\":\n",
        "                    if filename in self.test_filenames[c]:\n",
        "                        self.class_to_file[c].append(filename)\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid split name.\")\n",
        "\n",
        "        self.filepath_list = list()\n",
        "        self.label_list = list()\n",
        "        for cc, c in enumerate(self.get_classes()):\n",
        "            f_extension = sorted(list(self.class_to_file[c]))\n",
        "            l_extension = [cc for i in f_extension]\n",
        "            f_extension = [self.root_dir + \"/data_speech_commands_v0.02/\" + c + \"/\" + filename for filename in f_extension]\n",
        "            self.filepath_list.extend(f_extension)\n",
        "            self.label_list.extend(l_extension)\n",
        "        self.number_of_samples = len(self.filepath_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.number_of_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = np.zeros((16000, ), dtype=np.float32)\n",
        "\n",
        "        sample_file = self.filepath_list[idx]\n",
        "\n",
        "        sample_from_file = read(sample_file)[1]\n",
        "        sample[:sample_from_file.size] = sample_from_file\n",
        "        sample = sample.reshape((16000, ))\n",
        "        \n",
        "        # Experimenting with MFCC function configuration:\n",
        "        sample = librosa.feature.mfcc(y=sample, sr=16000, hop_length=512, n_fft=2048).transpose().astype(np.float32)\n",
        "        \n",
        "        label = self.label_list[idx]\n",
        "\n",
        "        return sample, label\n",
        "\n",
        "    def get_classes(self):\n",
        "        return ['one', 'two', 'three']\n",
        "\n",
        "    def get_valid_filenames(self):\n",
        "        class_names = self.get_classes()\n",
        "\n",
        "        class_to_filename = defaultdict(set)\n",
        "        with open(self.root_dir + \"/data_speech_commands_v0.02/validation_list.txt\", \"r\") as fp:\n",
        "            for line in fp:\n",
        "                clean_line = line.strip().split(\"/\")\n",
        "\n",
        "                if clean_line[0] in class_names:\n",
        "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
        "\n",
        "        return class_to_filename\n",
        "\n",
        "    def get_test_filenames(self):\n",
        "        class_names = self.get_classes()\n",
        "\n",
        "        class_to_filename = defaultdict(set)\n",
        "        with open(self.root_dir + \"/data_speech_commands_v0.02/testing_list.txt\", \"r\") as fp:\n",
        "            for line in fp:\n",
        "                clean_line = line.strip().split(\"/\")\n",
        "\n",
        "                if clean_line[0] in class_names:\n",
        "                    class_to_filename[clean_line[0]].add(clean_line[1])\n",
        "\n",
        "        return class_to_filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCJHwZhcKYPE"
      },
      "source": [
        "Load Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx8ptirGKa9u"
      },
      "source": [
        "## Dataset\n",
        "dataset_folder = \"./\"\n",
        "\n",
        "train_dataset = SpeechCommandsDataset(dataset_folder,\n",
        "                                      \"train\")\n",
        "valid_dataset = SpeechCommandsDataset(dataset_folder,\n",
        "                                      \"valid\")\n",
        "\n",
        "test_dataset = SpeechCommandsDataset(dataset_folder,\n",
        "                                     \"test\")\n",
        "\n",
        "batch_size = 20\n",
        "num_epochs = 3\n",
        "valid_every_n_steps = 20\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=False)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJwOesOQOSh9"
      },
      "source": [
        "## Part 1 \n",
        " \n",
        "Implementation of LSTMCell, BasicRNNCell and GRUCell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQu9Yxfy-Wqj"
      },
      "source": [
        "class LSTMCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(LSTMCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        \n",
        "        self.x2h = nn.Linear(self.input_size, self.hidden_size * 4, bias = self.bias)\n",
        "        self.h2h = nn.Linear(self.hidden_size, self.hidden_size * 4, bias = self.bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "        if hx is None:\n",
        "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
        "            hx = (hx, hx)\n",
        "            \n",
        "        x_t = input\n",
        "        h_t_p = hx[0]\n",
        "        c_t_p = hx[1]\n",
        "\n",
        "        # Define the current input, the sum of the input vector x_t and the previous hidden state vector, h_t_p\n",
        "        current_input = self.x2h(x_t) + self.h2h(h_t_p)\n",
        "\n",
        "        # Define the four gates and their activations\n",
        "        igate, fgate, ggate, ogate = current_input.chunk(4, 1)\n",
        "\n",
        "        igate = torch.sigmoid(igate)\n",
        "        fgate = torch.sigmoid(fgate)\n",
        "        ggate = torch.tanh(ggate)\n",
        "        ogate = torch.sigmoid(ogate)\n",
        "\n",
        "        # Compute new cell state\n",
        "        c_t = fgate * c_t_p + igate * ggate\n",
        "\n",
        "        # Compute candidate hidden state values to output\n",
        "        h_cand_t = torch.tanh(c_t)\n",
        "\n",
        "        # Compute actual hidden state values to output using output gate activations\n",
        "        h_t = ogate * h_cand_t\n",
        "\n",
        "        hy = h_t\n",
        "        cy = c_t\n",
        "\n",
        "        return (hy, cy)\n",
        "\n",
        "class BasicRNNCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True, nonlinearity=\"tanh\"):\n",
        "        super(BasicRNNCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "        self.nonlinearity = nonlinearity\n",
        "        if self.nonlinearity not in [\"tanh\", \"relu\"]:\n",
        "            raise ValueError(\"Invalid nonlinearity selected for RNN.\")\n",
        "\n",
        "        self.x2h = nn.Linear(input_size, hidden_size, bias=bias)\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size, bias=bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "        \n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "            \n",
        "    def forward(self, input, hx=None):\n",
        "        if hx is None:\n",
        "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
        "\n",
        "        hy = self.x2h(input) + self.h2h(hx)\n",
        "        if self.nonlinearity == 'tanh':\n",
        "            hy = torch.tanh(hy)\n",
        "        elif self.nonlinearity == 'relu':\n",
        "            hy = torch.relu(hy)\n",
        "            \n",
        "        return hy\n",
        "\n",
        "    \n",
        "    \n",
        "class GRUCell(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, bias=True):\n",
        "        super(GRUCell, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bias = bias\n",
        "\n",
        "        self.x2h = nn.Linear(self.input_size, self.hidden_size * 3, bias = self.bias)\n",
        "        self.h2h = nn.Linear(self.hidden_size, self.hidden_size * 3, bias = self.bias)\n",
        "\n",
        "        self.reset_parameters()\n",
        "        \n",
        "\n",
        "    def reset_parameters(self):\n",
        "        std = 1.0 / math.sqrt(self.hidden_size)\n",
        "        for w in self.parameters():\n",
        "            w.data.uniform_(-std, std)\n",
        "\n",
        "    def forward(self, input, hx=None):\n",
        "        if hx is None:\n",
        "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
        "\n",
        "        x, h = self.x2h(input), self.h2h(hx)\n",
        "\n",
        "        # Gates:\n",
        "        xr, xz, xo = x.chunk(3, 1)\n",
        "        hr, hz, ho = h.chunk(3, 1)\n",
        "        rgate = xr + hr\n",
        "        ugate = xz + hz\n",
        "        rgate = torch.sigmoid(rgate)\n",
        "        ugate = torch.sigmoid(ugate)\n",
        "        hgate = xo + rgate * ho \n",
        "        hgate = torch.tanh(hgate)\n",
        "\n",
        "        hy = ((1 - ugate) * hx) + (ugate * hgate)\n",
        "        \n",
        "        return hy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fu2N8UgeoWG"
      },
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bias = bias\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.rnn_cell_list = nn.ModuleList()\n",
        "        \n",
        "        if mode == 'LSTM':\n",
        "            self.rnn_cell_list.append(LSTMCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list.append(LSTMCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "\n",
        "\n",
        "        elif mode == 'GRU':\n",
        "            self.rnn_cell_list.append(GRUCell(self.input_size,\n",
        "                                              self.hidden_size,\n",
        "                                              self.bias))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list.append(GRUCell(self.hidden_size,\n",
        "                                                  self.hidden_size,\n",
        "                                                  self.bias))\n",
        "\n",
        "        elif mode == 'RNN_TANH':\n",
        "            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias,\n",
        "                                                   \"tanh\"))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n",
        "                                                       self.hidden_size,\n",
        "                                                       self.bias,\n",
        "                                                       \"tanh\"))\n",
        "\n",
        "        elif mode == 'RNN_RELU':\n",
        "            self.rnn_cell_list.append(BasicRNNCell(self.input_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias,\n",
        "                                                   \"relu\"))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list.append(BasicRNNCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias,\n",
        "                                                   \"relu\"))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid RNN mode selected.\")\n",
        "\n",
        "\n",
        "        self.att_fc = nn.Linear(self.hidden_size, 1)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.output_size * 32)\n",
        "\n",
        "        \n",
        "    def forward(self, input, hx=None):\n",
        "        if hx is None:\n",
        "            if torch.cuda.is_available():\n",
        "                h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size).cuda())\n",
        "            else:\n",
        "                h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size))\n",
        "\n",
        "        else:\n",
        "             h0 = hx\n",
        "\n",
        "        outs = []\n",
        "\n",
        "        sequence_length = input.size()[1] \n",
        "\n",
        "        # Loop over number of layers:\n",
        "        for layer in range(self.num_layers):\n",
        "            if layer == 0:\n",
        "                # Loop over length of sequence\n",
        "                for j in range(sequence_length):\n",
        "                    if j == 0:\n",
        "                        hx = self.rnn_cell_list[layer].forward(input[:,j,:], None)\n",
        "                    else:\n",
        "                        hx = self.rnn_cell_list[layer].forward(input[:,j,:], hx)\n",
        "                    outs.append(hx)\n",
        "            else: \n",
        "                if self.mode == 'LSTM':\n",
        "                    # Loop over length of sequence\n",
        "                    for j in range(sequence_length):\n",
        "                        if j == 0:\n",
        "                            outs[j] = self.rnn_cell_list[layer].forward(outs[j][0], None)\n",
        "                        else:\n",
        "                            outs[j] = self.rnn_cell_list[layer].forward(outs[j][0], outs[j-1])\n",
        "                else:\n",
        "                    # Loop over length of sequence\n",
        "                    for j in range(sequence_length):\n",
        "                        if j == 0:\n",
        "                            outs[j] = self.rnn_cell_list[layer].forward(outs[j], None)\n",
        "                        else:\n",
        "                            outs[j] = self.rnn_cell_list[layer].forward(outs[j], outs[j-1])\n",
        "\n",
        "        if self.mode == 'LSTM':\n",
        "            outs = [outs[i][0] for i in range(len(outs))]\n",
        "\n",
        "        # Experiments for Part 3:\n",
        "        # Taking the final hidden state only:\n",
        "        #out = outs[-1].squeeze() # Related to Part 3.\n",
        "\n",
        "        # Using all hidden states\n",
        "        outs = [outs[i].squeeze() for i in range(len(outs))]\n",
        "\n",
        "        # Taking the final hidden state only:\n",
        "        # out = self.fc(out)\n",
        "\n",
        "        # Using all hidden states:\n",
        "        out = [self.fc(out) for out in outs]\n",
        "        \n",
        "        return out\n",
        "    \n",
        "\n",
        "class BidirRecurrentModel(nn.Module):\n",
        "    def __init__(self, mode, input_size, hidden_size, num_layers, bias, output_size):\n",
        "        super(BidirRecurrentModel, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.bias = bias\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.rnn_cell_list = nn.ModuleList()\n",
        "        \n",
        "        self.rnn_cell_list_forward = nn.ModuleList()\n",
        "        self.rnn_cell_list_backward = nn.ModuleList()\n",
        "        if mode == 'Bi_LSTM':\n",
        "            self.rnn_cell_list_forward.append(LSTMCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            self.rnn_cell_list_backward.append(LSTMCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list_forward.append(LSTMCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "                self.rnn_cell_list_backward.append(LSTMCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "\n",
        "        elif mode == 'Bi_GRU':\n",
        "            self.rnn_cell_list_forward.append(GRUCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            self.rnn_cell_list_backward.append(GRUCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list_forward.append(GRUCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "                self.rnn_cell_list_backward.append(GRUCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "\n",
        "        elif mode == 'Bi_RNN_TANH':\n",
        "            self.rnn_cell_list_forward.append(BasicRNNCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            self.rnn_cell_list_backward.append(BasicRNNCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list_forward.append(BasicRNNCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "                self.rnn_cell_list_backward.append(BasicRNNCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "\n",
        "        elif mode == 'Bi_RNN_RELU':\n",
        "            self.rnn_cell_list_forward.append(BasicRNNCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            self.rnn_cell_list_backward.append(BasicRNNCell(self.input_size,\n",
        "                                               self.hidden_size,\n",
        "                                               self.bias))\n",
        "            for l in range(1, self.num_layers):\n",
        "                self.rnn_cell_list_forward.append(BasicRNNCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "                self.rnn_cell_list_backward.append(BasicRNNCell(self.hidden_size,\n",
        "                                                   self.hidden_size,\n",
        "                                                   self.bias))\n",
        "        else:\n",
        "            raise ValueError(\"Invalid Bidirectional RNN mode selected.\")\n",
        "\n",
        "        self.att_fc = nn.Linear(self.hidden_size * 2, 1)\n",
        "        self.fc1 = nn.Linear(self.hidden_size * 2, self.output_size)\n",
        "        self.fc2 = nn.Linear(self.output_size * 32, self.output_size)\n",
        "        \n",
        "        \n",
        "    def forward(self, input, hx=None):\n",
        "        if torch.cuda.is_available():\n",
        "            h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size).cuda())\n",
        "        else:\n",
        "            h0 = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size))\n",
        "            \n",
        "        if torch.cuda.is_available():\n",
        "            hT = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size).cuda())\n",
        "        else:\n",
        "            hT = Variable(torch.zeros(self.num_layers, input.size(0), self.hidden_size))\n",
        "            \n",
        "            \n",
        "        outs = []\n",
        "        outs_rev = []\n",
        "        \n",
        "        direction = ['forward', 'backward']\n",
        "        sequence_length = input.size()[1] \n",
        "\n",
        "        for d in direction:\n",
        "            if d == 'forward':\n",
        "                # Loop over number of layers:\n",
        "                for layer in range(self.num_layers):\n",
        "                    if layer == 0:\n",
        "                        # Loop over length of sequence\n",
        "                        for j in range(sequence_length):\n",
        "                            if j == 0:\n",
        "                                hx = self.rnn_cell_list_forward[layer].forward(input[:,j,:], None)\n",
        "                            else:\n",
        "                                hx = self.rnn_cell_list_forward[layer].forward(input[:,j,:], hx)\n",
        "                            outs.append(hx)\n",
        "                    else: \n",
        "                        if self.mode == 'Bi_LSTM':\n",
        "                            # Loop over length of sequence\n",
        "                            for j in range(sequence_length):\n",
        "                                if j == 0:\n",
        "                                    outs[j] = self.rnn_cell_list_forward[layer].forward(outs[j][0], None)\n",
        "                                else:\n",
        "                                    outs[j] = self.rnn_cell_list_forward[layer].forward(outs[j][0], outs[j-1])\n",
        "                        else:\n",
        "                            # Loop over length of sequence\n",
        "                            for j in range(sequence_length):\n",
        "                                if j == 0:\n",
        "                                    outs[j] = self.rnn_cell_list_forward[layer].forward(outs[j], None)\n",
        "                                else:\n",
        "                                    outs[j] = self.rnn_cell_list_forward[layer].forward(outs[j], outs[j-1])\n",
        "                if self.mode == 'Bi_LSTM':\n",
        "                    outs = [outs[i][0] for i in range(len(outs))]\n",
        "            elif d == 'backward':\n",
        "                # Loop over number of layers:\n",
        "                for layer in range(self.num_layers):\n",
        "                    if layer == 0:\n",
        "                        # Loop over length of sequence\n",
        "                        for j in range(sequence_length-1,-1,-1):\n",
        "                            if j == sequence_length-1:\n",
        "                                hx = self.rnn_cell_list_backward[layer].forward(input[:,j,:], None)\n",
        "                            else:\n",
        "                                hx = self.rnn_cell_list_backward[layer].forward(input[:,j,:], hx)\n",
        "                            outs_rev.append(hx)\n",
        "                    else: \n",
        "                        if self.mode == 'Bi_LSTM':\n",
        "                            # Loop over length of sequence\n",
        "                            for j in range(sequence_length-1,-1,-1):\n",
        "                                if j == sequence_length-1:\n",
        "                                    outs_rev[j] = self.rnn_cell_list_backward[layer].forward(outs_rev[j][0], None)\n",
        "                                else:\n",
        "                                    outs_rev[j] = self.rnn_cell_list_backward[layer].forward(outs_rev[j][0], outs_rev[j-1])\n",
        "                        else:\n",
        "                            # Loop over length of sequence\n",
        "                            for j in range(sequence_length-1,-1,-1):\n",
        "                                if j == sequence_length-1:\n",
        "                                    outs_rev[j] = self.rnn_cell_list_backward[layer].forward(outs_rev[j], None)\n",
        "                                else:\n",
        "                                    outs_rev[j] = self.rnn_cell_list_backward[layer].forward(outs_rev[j], outs_rev[j-1])\n",
        "                if self.mode == 'Bi_LSTM':\n",
        "                    outs_rev = [outs_rev[i][0] for i in range(len(outs_rev))]\n",
        "\n",
        "        '''out = outs[-1].squeeze()  \n",
        "        out_rev = outs_rev[0].squeeze()\n",
        "        out = torch.cat((out, out_rev), 1)\n",
        "\n",
        "        out = self.fc(out)'''\n",
        "\n",
        "        # Experiments for Part 3:\n",
        "        # Using all hidden states\n",
        "        outs_cat = [torch.cat((outs[i], outs_rev[i]), 1) for i in range(len(outs))]\n",
        "\n",
        "        # Using all hidden states:\n",
        "        out_pred = [self.fc1(outs_cat[j]) for j in range(len(outs_cat))]\n",
        "        out_pred_ensemble = torch.cat(tuple(out_pred), 1)\n",
        "\n",
        "        # Ensemble prediction\n",
        "        out = self.fc2(out_pred_ensemble)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWnA4hp8eoWR"
      },
      "source": [
        "## Part 2\n",
        "\n",
        "Experimented with different RNN architectures (RNN cell types, number of layers, hidden state dimensionality, MFCC configuration, unidirectional VS bidirectional) and reported the accuracy as well as training time. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVBdvUZseoWV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23872f0f-21e1-4f38-d2a9-d52ce06bdec2"
      },
      "source": [
        "# Parts of experiment code based on: https://github.com/emadRad/lstm-gru-pytorch\n",
        "import time\n",
        "seq_dim, input_dim = train_dataset[0][0].shape\n",
        "output_dim = 3\n",
        "hidden_dim = 64\n",
        "layer_dim = 4\n",
        "bias = True\n",
        "\n",
        "model = RNNModel(\"LSTM\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
        "# model = BidirRecurrentModel(\"Bi_LSTM\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_list = []\n",
        "iter = 0\n",
        "max_v_accuracy = 0\n",
        "reported_t_accuracy = 0\n",
        "max_t_accuracy = 0\n",
        "t_before = time.clock()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (audio, labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
        "            labels = Variable(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(audio)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        iter += 1\n",
        "\n",
        "        if iter % valid_every_n_steps == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for audio, labels in valid_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
        "                else:\n",
        "                    audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
        "\n",
        "                outputs = model(audio)\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            v_accuracy = 100 * correct / total\n",
        "            \n",
        "            is_best = False\n",
        "            if v_accuracy >= max_v_accuracy:\n",
        "                max_v_accuracy = v_accuracy\n",
        "                is_best = True\n",
        "\n",
        "            if is_best:\n",
        "                for audio, labels in test_loader:\n",
        "                    if torch.cuda.is_available():\n",
        "                        audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
        "                    else:\n",
        "                        audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
        "\n",
        "                    outputs = model(audio)\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    total += labels.size(0)\n",
        "\n",
        "                    if torch.cuda.is_available():\n",
        "                        correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                    else:\n",
        "                        correct += (predicted == labels).sum()\n",
        "\n",
        "                t_accuracy = 100 * correct / total\n",
        "                reported_t_accuracy = t_accuracy\n",
        "\n",
        "            print('Iteration: {}. Loss: {}. V-Accuracy: {}  T-Accuracy: {}'.format(iter, loss.item(), v_accuracy, reported_t_accuracy))\n",
        "\n",
        "training_time = time.clock() - t_before\n",
        "print('Training time: ' + str(training_time) + ' seconds \\n')\n",
        "print('Training time: ' + str(training_time / 60.0) + ' minutes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 20. Loss: 1.0984433889389038. V-Accuracy: 33  T-Accuracy: 33\n",
            "Iteration: 40. Loss: 1.0906832218170166. V-Accuracy: 43  T-Accuracy: 46\n",
            "Iteration: 60. Loss: 1.0014851093292236. V-Accuracy: 61  T-Accuracy: 59\n",
            "Iteration: 80. Loss: 0.7186201214790344. V-Accuracy: 69  T-Accuracy: 68\n",
            "Iteration: 100. Loss: 0.8055158853530884. V-Accuracy: 75  T-Accuracy: 73\n",
            "Iteration: 120. Loss: 0.45969128608703613. V-Accuracy: 81  T-Accuracy: 79\n",
            "Iteration: 140. Loss: 0.4297122061252594. V-Accuracy: 81  T-Accuracy: 80\n",
            "Iteration: 160. Loss: 0.3701402544975281. V-Accuracy: 77  T-Accuracy: 80\n",
            "Iteration: 180. Loss: 0.3631555736064911. V-Accuracy: 82  T-Accuracy: 82\n",
            "Iteration: 200. Loss: 0.5101146697998047. V-Accuracy: 85  T-Accuracy: 84\n",
            "Iteration: 220. Loss: 0.3955325484275818. V-Accuracy: 86  T-Accuracy: 85\n",
            "Iteration: 240. Loss: 0.4306756854057312. V-Accuracy: 87  T-Accuracy: 86\n",
            "Iteration: 260. Loss: 0.5295273065567017. V-Accuracy: 87  T-Accuracy: 87\n",
            "Iteration: 280. Loss: 0.25445204973220825. V-Accuracy: 86  T-Accuracy: 87\n",
            "Iteration: 300. Loss: 0.6059735417366028. V-Accuracy: 89  T-Accuracy: 87\n",
            "Iteration: 320. Loss: 0.3611169457435608. V-Accuracy: 89  T-Accuracy: 88\n",
            "Iteration: 340. Loss: 0.3128899931907654. V-Accuracy: 93  T-Accuracy: 91\n",
            "Iteration: 360. Loss: 0.441537469625473. V-Accuracy: 91  T-Accuracy: 91\n",
            "Iteration: 380. Loss: 0.19638237357139587. V-Accuracy: 92  T-Accuracy: 91\n",
            "Iteration: 400. Loss: 0.42798954248428345. V-Accuracy: 88  T-Accuracy: 91\n",
            "Iteration: 420. Loss: 0.3350875973701477. V-Accuracy: 91  T-Accuracy: 91\n",
            "Iteration: 440. Loss: 0.3275063931941986. V-Accuracy: 92  T-Accuracy: 91\n",
            "Iteration: 460. Loss: 0.09023724496364594. V-Accuracy: 91  T-Accuracy: 91\n",
            "Iteration: 480. Loss: 0.15912966430187225. V-Accuracy: 92  T-Accuracy: 91\n",
            "Iteration: 500. Loss: 0.21675901114940643. V-Accuracy: 91  T-Accuracy: 91\n",
            "Iteration: 520. Loss: 0.30030539631843567. V-Accuracy: 93  T-Accuracy: 93\n",
            "Iteration: 540. Loss: 0.31386566162109375. V-Accuracy: 93  T-Accuracy: 93\n",
            "Iteration: 560. Loss: 0.18404239416122437. V-Accuracy: 92  T-Accuracy: 93\n",
            "Iteration: 580. Loss: 0.2845551073551178. V-Accuracy: 94  T-Accuracy: 93\n",
            "Iteration: 600. Loss: 0.4203578531742096. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 620. Loss: 0.12215067446231842. V-Accuracy: 92  T-Accuracy: 94\n",
            "Iteration: 640. Loss: 0.3748895227909088. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 660. Loss: 0.4193974435329437. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 680. Loss: 0.41821223497390747. V-Accuracy: 94  T-Accuracy: 93\n",
            "Iteration: 700. Loss: 0.19760820269584656. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 720. Loss: 0.45932045578956604. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 740. Loss: 0.12152409553527832. V-Accuracy: 92  T-Accuracy: 94\n",
            "Iteration: 760. Loss: 0.09948985278606415. V-Accuracy: 90  T-Accuracy: 94\n",
            "Iteration: 780. Loss: 0.04265470430254936. V-Accuracy: 92  T-Accuracy: 94\n",
            "Iteration: 800. Loss: 0.08791397511959076. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 820. Loss: 0.28960949182510376. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 840. Loss: 0.09076949208974838. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 860. Loss: 0.24938395619392395. V-Accuracy: 91  T-Accuracy: 94\n",
            "Iteration: 880. Loss: 0.15983542799949646. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 900. Loss: 0.13347315788269043. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 920. Loss: 0.3031574785709381. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 940. Loss: 0.202475905418396. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 960. Loss: 0.33526095747947693. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 980. Loss: 0.1542787253856659. V-Accuracy: 91  T-Accuracy: 94\n",
            "Iteration: 1000. Loss: 0.4509054124355316. V-Accuracy: 92  T-Accuracy: 94\n",
            "Iteration: 1020. Loss: 0.1702118068933487. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 1040. Loss: 0.4067663550376892. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 1060. Loss: 0.7706879377365112. V-Accuracy: 92  T-Accuracy: 94\n",
            "Iteration: 1080. Loss: 0.17353349924087524. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 1100. Loss: 0.16086478531360626. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 1120. Loss: 0.16109879314899445. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 1140. Loss: 0.1672404706478119. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 1160. Loss: 0.5386630892753601. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 1180. Loss: 0.23254013061523438. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 1200. Loss: 0.03831978887319565. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 1220. Loss: 0.1356779932975769. V-Accuracy: 95  T-Accuracy: 94\n",
            "Iteration: 1240. Loss: 0.03486564755439758. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 1260. Loss: 0.17310655117034912. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 1280. Loss: 0.07560183107852936. V-Accuracy: 93  T-Accuracy: 94\n",
            "Iteration: 1300. Loss: 0.2682267129421234. V-Accuracy: 94  T-Accuracy: 94\n",
            "Iteration: 1320. Loss: 0.2953930199146271. V-Accuracy: 95  T-Accuracy: 95\n",
            "Iteration: 1340. Loss: 0.02985289692878723. V-Accuracy: 94  T-Accuracy: 95\n",
            "Iteration: 1360. Loss: 0.08320493996143341. V-Accuracy: 94  T-Accuracy: 95\n",
            "Iteration: 1380. Loss: 0.0923379436135292. V-Accuracy: 93  T-Accuracy: 95\n",
            "Training time: 5024.267128 seconds \n",
            "\n",
            "Training time: 83.73778546666668 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2DGOnTffxvH"
      },
      "source": [
        "#################### Experimental Results for Part 1.2 #####################\n",
        "from IPython.display import Image, display\n",
        "display(Image(filename='results_table.png', width=1300))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0H6oJyOX-W7n"
      },
      "source": [
        "## Part 3 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx-QwUHfeoWf"
      },
      "source": [
        "## Discussion about Predictions.\n",
        "\n",
        "Utilising the final hidden state may not be the best choice to make a final prediction because it only uses the hidden representation of the last part of the audio sample to make a classification. For a larger number of classes, the last hidden state in the sequence may be very similar since the word may have the same phoneme at the end. This is equivalent to only using only a small region of a feature map after a convolutional layer when trying to classify on image, many images of different classes can have similar looking local regions. This can lead to lots of false positives. \n",
        "\n",
        "Variations on final prediction:\n",
        "\n",
        "\n",
        "*   Instead of using only the last hidden state: an average over all hidden states can be computed which is then fed into the FC; or, each hidden state can be fed into the FC to 32 individual predictions, and then the final prediction is the majority vote out of these 32. \n",
        "\n",
        "*   Better still, certain frames in the audio sample may be more important than others. Attention can therefore be applied at the output to use a weighted average of the hidden states to feed into the FC layer to make a final prediction. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9ssHUJKeoWh"
      },
      "source": [
        "# Parts of experiment code based on: https://github.com/emadRad/lstm-gru-pytorch\n",
        "\n",
        "from collections import Counter\n",
        "import time\n",
        "\n",
        "seq_dim, input_dim = train_dataset[0][0].shape\n",
        "output_dim = 3\n",
        "hidden_dim = 64\n",
        "layer_dim = 4\n",
        "bias = True\n",
        "\n",
        "# model = RNNModel(\"LSTM\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
        "model = BidirRecurrentModel(\"Bi_GRU\", input_dim, hidden_dim, layer_dim, bias, output_dim)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "    \n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_list = []\n",
        "iter = 0\n",
        "max_v_accuracy = 0\n",
        "reported_t_accuracy = 0\n",
        "max_t_accuracy = 0\n",
        "t_before = time.clock()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (audio, labels) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "        else:\n",
        "            audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
        "            labels = Variable(labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(audio)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        '''\n",
        "        losses = torch.FloatTensor([criterion(outputs[i], labels) for i in range(len(outputs))]).cuda()\n",
        "        loss = torch.mean(losses)\n",
        "        loss.requires_grad = True\n",
        "        '''\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            loss.cuda()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_list.append(loss.item())\n",
        "        iter += 1\n",
        "\n",
        "        if iter % valid_every_n_steps == 0:\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for audio, labels in valid_loader:\n",
        "                if torch.cuda.is_available():\n",
        "                    audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
        "                else:\n",
        "                    audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
        "\n",
        "                outputs = model(audio)\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                '''\n",
        "                #print(outputs[0].data)\n",
        "                predicted = [torch.max(outputs[i].data, 1)[1] for i in range(len(outputs))]\n",
        "                print(predicted[0]\n",
        "                predicted = Counter([predicted[j][1] for j in range(len(predicted))]).most_common(1)\n",
        "                predicted = predicted[0][0].item()\n",
        "                '''\n",
        "\n",
        "                total += labels.size(0)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            v_accuracy = 100 * correct / total\n",
        "            \n",
        "            is_best = False\n",
        "            if v_accuracy >= max_v_accuracy:\n",
        "                max_v_accuracy = v_accuracy\n",
        "                is_best = True\n",
        "\n",
        "            if is_best:\n",
        "                for audio, labels in test_loader:\n",
        "                    if torch.cuda.is_available():\n",
        "                        audio = Variable(audio.view(-1, seq_dim, input_dim).cuda())\n",
        "                    else:\n",
        "                        audio = Variable(audio.view(-1, seq_dim, input_dim))\n",
        "\n",
        "                    outputs = model(audio)\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    '''\n",
        "                    predicted = [torch.max(outputs[i].data, 1) for i in range(len(outputs))]\n",
        "                    predicted = Counter([predicted[j][1] for j in range(len(predicted))]).most_common(1)\n",
        "                    predicted = predicted[0][0]\n",
        "                    '''\n",
        "\n",
        "                    total += labels.size(0)\n",
        "\n",
        "                    if torch.cuda.is_available():\n",
        "                        correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                    else:\n",
        "                        correct += (predicted == labels).sum()\n",
        "\n",
        "                t_accuracy = 100 * correct / total\n",
        "                reported_t_accuracy = t_accuracy\n",
        "\n",
        "            print('Iteration: {}. Loss: {}. V-Accuracy: {}  T-Accuracy: {}'.format(iter, loss.item(), v_accuracy, reported_t_accuracy))\n",
        "\n",
        "training_time = time.clock() - t_before\n",
        "print('Training time: ' + str(training_time) + ' seconds \\n')\n",
        "print('Training time: ' + str(training_time / 60.0) + ' minutes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha2y337Li6b4"
      },
      "source": [
        "### Short discussion on the vanishing/exploding gradient problem.\n",
        "\n",
        "Vanishing and exploding gradients appear when calculating the derivative of the loss with respect to the weights in an RNN. It occurs because parameters are shared across each time step, so the gradient of the loss with respect to a single parameter $w$ consists of contributions from every path from $w$ to the loss. Each of these paths consists of a product of the parameter matrices due to the chain rule, and the further back the start of the path from the current time-step, the more matrix multiplications there are in the gradient. If the parameter is less than 1. \n",
        "\n",
        "Therefore, for large sequences, the relative influence of gradients w.r.t $w$ from much older time-steps vanishes if the parameter is less than 1, or explodes and dominates if the parameter is greater than 1. This means that information from past time-steps does not improve the current prediction since relationships are lost between distant states in the sequence. In practical terms, the update to $w$ is dominated by more recent gradients in the sequene if vanishing. In the exploding case, the update to $w$ is disproportionately dominated by older terms, effectively overwriting any prior learning. \n",
        "\n",
        "LSTMs mitigate this problem. Even though these gradient products exist over long sequences, the gradient is redeemed because the new state interacts in an additive way with the old state, instead of  through a purely multiplicative interaction. This means influence from the past never truly disappears unless, for example, the forget gate is closed. This improve gradient flow means the memory is stored over longer time periods. "
      ]
    }
  ]
}
